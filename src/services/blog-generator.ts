import { App, TFile, TFolder } from "obsidian";
import { GeminiClient, ImageData, showError, showSuccess } from "../utils/api-client";
import type { PaperProcessorSettings } from "../settings";
import { arxivCategoriesToTags, extractTopicTags, addWikilinks } from "../utils/obsidian-format";

export interface BlogResult {
  success: boolean;
  content?: string;
  path?: string;
  error?: string;
}

export interface BlogProgress {
  stage: "analyzing" | "generating" | "saving" | "complete";
  message: string;
  percent: number;
}

// Obsidian-specific formatting instructions
const OBSIDIAN_FORMAT_INSTRUCTIONS = `
OBSIDIAN FORMATTING (MUST FOLLOW):
- Use wikilinks for key concepts: [[Concept Name]] (e.g., [[Transformer]], [[RAG]], [[Fine-tuning]])
- Use Obsidian callouts for important sections:
  > [!tip] Title
  > Content here

  > [!note] Note
  > Content here

  > [!warning] Caution
  > Content here

  > [!abstract] Abstract
  > Content here

- Add a "Related Concepts" section at the end with wikilinks to related topics
- Use #tags inline where appropriate (e.g., "This uses #attention-mechanism and #transformer architecture")
`;

// Markdown formatting rules - CRITICAL
const MARKDOWN_FORMATTING_RULES = `
## ë§ˆí¬ë‹¤ìš´ í¬ë§·íŒ… ê·œì¹™ (í•„ìˆ˜ ì¤€ìˆ˜!)

**1. ë¶ˆë¦¿ í¬ì¸íŠ¸ ì ê·¹ í™œìš© (MUST)**
ëª¨ë“  ì„¹ì…˜ì—ì„œ ë¶ˆë¦¿ í¬ì¸íŠ¸ë¥¼ ì ê·¹ì ìœ¼ë¡œ ì‚¬ìš©í•˜ì„¸ìš”:

- 3ê°œ ì´ìƒ ë‚˜ì—´ë˜ëŠ” í•­ëª©ì€ ë°˜ë“œì‹œ ë¶ˆë¦¿ìœ¼ë¡œ
- ë‹¨ê³„ë³„ ì„¤ëª…ì€ ë²ˆí˜¸ ë§¤ê¸°ê¸° (1., 2., 3.)
- í•˜ìœ„ í•­ëª©ì€ ë“¤ì—¬ì“°ê¸° ë¶ˆë¦¿ (  - ë˜ëŠ”   *)
- ëŒ€ì¡°/ë¹„êµëŠ” ë¶ˆë¦¿ìœ¼ë¡œ ë³‘ë ¬ êµ¬ì¡°

**2. ê³„ì¸µ êµ¬ì¡° í‘œí˜„**
\`\`\`markdown
- **ìƒìœ„ ê°œë…**
  - í•˜ìœ„ ì„¤ëª… 1
  - í•˜ìœ„ ì„¤ëª… 2
    - ì„¸ë¶€ ì‚¬í•­ a
    - ì„¸ë¶€ ì‚¬í•­ b
\`\`\`

**3. ë³¼ë“œ/ì´íƒ¤ë¦­ ì‚¬ìš©**
- **í•µì‹¬ ìš©ì–´**, **ìˆ˜ì¹˜**, **ëª¨ë¸ëª…**ì€ ë°˜ë“œì‹œ ë³¼ë“œ
- *ê°•ì¡°í•˜ê³  ì‹¶ì€ ë¶€ì—° ì„¤ëª…*ì€ ì´íƒ¤ë¦­
- \`ì½”ë“œ\`, \`í•˜ì´í¼íŒŒë¼ë¯¸í„°ëª…\`, \`ë°ì´í„°ì…‹ëª…\`ì€ ì¸ë¼ì¸ ì½”ë“œ

**4. ìˆ˜ì‹ í‘œí˜„**
- ì¸ë¼ì¸ ìˆ˜ì‹: $x = W_q \\cdot h$
- ë¸”ë¡ ìˆ˜ì‹ (ì¤‘ìš” ìˆ˜ì‹):
$$
\\mathcal{L} = \\sum_{i=1}^{N} -\\log p(y_i | x_i)
$$

**5. í‘œ ì‚¬ìš© (ë¹„êµ/ì‹¤í—˜ ê²°ê³¼)**
| Method | F1 | Latency |
|--------|-----|---------|
| Baseline | 82.3 | 45ms |
| **Ours** | **87.3** | **12ms** |

**6. ì½œì•„ì›ƒ ë°•ìŠ¤**
> [!note] í•µì‹¬ í¬ì¸íŠ¸
> ì´ ë°©ë²•ì˜ í•µì‹¬ì€ query-conditional selectionì´ë‹¤.

> [!tip] ì‹¤ë¬´ ì ìš©
> ëŒ€ê·œëª¨ ê²€ìƒ‰ ì‹œìŠ¤í…œì— ì ìš© ì‹œ ì§€ì—°ì‹œê°„ 71% ê°ì†Œ ê¸°ëŒ€.
`;

// Critical image description instructions
const IMAGE_DESCRIPTION_INSTRUCTIONS = `
## ì´ë¯¸ì§€ í•´ì„¤ ê·œì¹™ (ì ˆëŒ€ í•„ìˆ˜ - ì´ ê·œì¹™ì„ ì–´ê¸°ë©´ ì•ˆ ë¨!)

**âš ï¸ ê²½ê³ : ëª¨ë“  ì´ë¯¸ì§€ëŠ” ë°˜ë“œì‹œ 20-30ì¤„ ì´ìƒì˜ í•™ìˆ ì  í•´ì„¤ì´ í•„ìš”í•©ë‹ˆë‹¤.**
**ì§§ì€ ì„¤ëª…(10ì¤„ ë¯¸ë§Œ)ì€ ì ˆëŒ€ í—ˆìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.**

### í•„ìˆ˜ êµ¬ì¡° (ëª¨ë“  ì´ë¯¸ì§€ì— ì ìš©)

ê° ì´ë¯¸ì§€ ë°”ë¡œ ì•„ë˜ì— ë‹¤ìŒ 5ê°œ ì„¹ì…˜ì„ **ë¶ˆë¦¿ í¬ì¸íŠ¸ë¡œ** ì‘ì„±:

#### ì„¹ì…˜ 1: ì „ì²´ êµ¬ì¡° ê°œìš” (3-4ì¤„)
- ì´ ê·¸ë¦¼ì´ ë…¼ë¬¸ì˜ ì–´ë–¤ ì„¹ì…˜/ê°œë…ì„ ì‹œê°í™”í•˜ëŠ”ì§€ ëª…ì‹œ
- ì „ì²´ì ì¸ ë°ì´í„°/ì •ë³´ì˜ íë¦„ ë°©í–¥ (ì™¼ìª½â†’ì˜¤ë¥¸ìª½, ìœ„â†’ì•„ë˜ ë“±)
- ì£¼ìš” ì»´í¬ë„ŒíŠ¸ ê°œìˆ˜ì™€ ì—­í•  ìš”ì•½

#### ì„¹ì…˜ 2: ì»´í¬ë„ŒíŠ¸ë³„ ìƒì„¸ ì„¤ëª… (8-10ì¤„)
ê° ë¸”ë¡/ëª¨ë“ˆë§ˆë‹¤ **ë³¼ë“œ ì œëª© + ë¶ˆë¦¿ ë¦¬ìŠ¤íŠ¸**:

**[ì»´í¬ë„ŒíŠ¸ A ì´ë¦„] (ìœ„ì¹˜ ì„¤ëª…)**
- ì—­í• : ë¬´ì—‡ì„ í•˜ëŠ” ëª¨ë“ˆì¸ì§€
- ì…ë ¥: ì–´ë–¤ í˜•íƒœì˜ ë°ì´í„°ê°€ ë“¤ì–´ì˜¤ëŠ”ì§€ (ì°¨ì› í¬í•¨)
- ì²˜ë¦¬: ë‚´ë¶€ì—ì„œ ì–´ë–¤ ì—°ì‚°ì´ ì¼ì–´ë‚˜ëŠ”ì§€
- ì¶œë ¥: ì–´ë–¤ í˜•íƒœë¡œ ë‚˜ê°€ëŠ”ì§€
- ìˆ˜ì‹: í•´ë‹¹ë˜ë©´ LaTeXë¡œ $W_q \\in \\mathbb{R}^{d \\times k}$

**[ì»´í¬ë„ŒíŠ¸ B ì´ë¦„] (ìœ„ì¹˜ ì„¤ëª…)**
- ì—­í• : ...
- ì…ë ¥: ...
- (ë™ì¼ êµ¬ì¡° ë°˜ë³µ)

#### ì„¹ì…˜ 3: ë°ì´í„° íë¦„ ë‹¨ê³„ë³„ ì„¤ëª… (4-5ì¤„)
1. **ì…ë ¥ ë‹¨ê³„**: ì›ë³¸ ë°ì´í„° í˜•íƒœ, ì „ì²˜ë¦¬ ê³¼ì •
2. **ì¸ì½”ë”© ë‹¨ê³„**: ì„ë² ë”© ë³€í™˜, ì°¨ì› ë³€í™”
3. **í•µì‹¬ ì²˜ë¦¬ ë‹¨ê³„**: ë…¼ë¬¸ì˜ í•µì‹¬ contributionì´ ì ìš©ë˜ëŠ” ë¶€ë¶„
4. **ì¶œë ¥ ë‹¨ê³„**: ìµœì¢… ê²°ê³¼ë¬¼ì˜ í˜•íƒœì™€ ì˜ë¯¸

#### ì„¹ì…˜ 4: ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­ (4-5ì¤„)
- **í•˜ì´í¼íŒŒë¼ë¯¸í„°**: \`hidden_dim=768\`, \`num_layers=12\` ë“±
- **ê³„ì‚° ë³µì¡ë„**: $O(n^2)$ â†’ $O(n \\log n)$ ê°œì„ 
- **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**: ê¸°ì¡´ ëŒ€ë¹„ ëª‡ % ê°ì†Œ
- **í•™ìŠµ ì„¤ì •**: optimizer, learning rate, batch size

#### ì„¹ì…˜ 5: ì‹¤í—˜ ê²°ê³¼ ì—°ê³„ (3-4ì¤„, í‘œ/ê·¸ë˜í”„ì¸ ê²½ìš°)
- **ë² ì´ìŠ¤ë¼ì¸ ëŒ€ë¹„ ì„±ëŠ¥**: +5.2 F1, -23% latency
- **ìµœê³  ì„±ëŠ¥ ë‹¬ì„± ì¡°ê±´**: ì–´ë–¤ ì„¤ì •ì—ì„œ ìµœê³ ì¸ì§€
- **Ablation ê²°ê³¼**: ì–´ë–¤ ì»´í¬ë„ŒíŠ¸ê°€ ê°€ì¥ ì¤‘ìš”í•œì§€

---

### ì˜ˆì‹œ (ì´ ìˆ˜ì¤€ì˜ ìƒì„¸í•¨ í•„ìˆ˜):

![[images/img-1.png]]

**ê·¸ë¦¼ 1: Token Routing ì•„í‚¤í…ì²˜ì˜ ì „ì²´ êµ¬ì¡°**

ì´ ê·¸ë¦¼ì€ ë…¼ë¬¸ Section 3ì—ì„œ ì œì•ˆí•˜ëŠ” Token Routing ë©”ì»¤ë‹ˆì¦˜ì˜ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ë³´ì—¬ì¤€ë‹¤. ë°ì´í„°ëŠ” ì™¼ìª½ì—ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ íë¥´ë©°, í¬ê²Œ 3ê°œì˜ ì£¼ìš” ëª¨ë“ˆ(Query Encoder, Routing Module, Retrieval Head)ë¡œ êµ¬ì„±ëœë‹¤.

**1. Query Encoder (ì™¼ìª½ íŒŒë€ ë°•ìŠ¤)**
- **ì—­í• **: ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ dense embeddingìœ¼ë¡œ ë³€í™˜
- **ì•„í‚¤í…ì²˜**: BERT-base (\`12 layers\`, \`hidden_dim=768\`)
- **ì…ë ¥**: í…ìŠ¤íŠ¸ ì¿¼ë¦¬, ìµœëŒ€ 512 í† í°
- **ì¶œë ¥**: $\\mathbf{q} \\in \\mathbb{R}^{768}$
- **íŠ¹ì§•**: pretrained weights ì‚¬ìš©, fine-tuning ê°€ëŠ¥

**2. Routing Module (ì¤‘ì•™ ì£¼í™©ìƒ‰ ë¸”ë¡)**
- **ì—­í• **: query-conditionalí•˜ê²Œ ì¤‘ìš” í† í° ì„ íƒ
- **í•µì‹¬ ìˆ˜ì‹**: ë¼ìš°íŒ… ì ìˆ˜ $\\mathbf{s} = \\text{softmax}(W_r \\cdot \\mathbf{q})$
  - $W_r \\in \\mathbb{R}^{V \\times 768}$: í•™ìŠµ ê°€ëŠ¥í•œ ë¼ìš°íŒ… í–‰ë ¬
  - $V$: vocabulary size
- **Top-k ì„ íƒ**: ìƒìœ„ $k=16$ê°œ í† í°ë§Œ ì„ íƒ (ë…¼ë¬¸ Table 2ì—ì„œ ìµœì ê°’)
- **ì¥ì **: ê³„ì‚°ëŸ‰ **87.5% ê°ì†Œ** (128â†’16 í† í°)

**3. Retrieval Head (ì˜¤ë¥¸ìª½ ë…¹ìƒ‰ ë¸”ë¡)**
- **ì—­í• **: ì„ íƒëœ í† í°ìœ¼ë¡œ ë¬¸ì„œ ìœ ì‚¬ë„ ê³„ì‚°
- **ì—°ì‚°**: ì„ íƒëœ 16ê°œ í† í° ì„ë² ë”©ê³¼ ë¬¸ì„œ ì¸ì½”ë” ì¶œë ¥ì˜ ë‚´ì 
- **ì ì„  í™”ì‚´í‘œ**: ì—­ì „íŒŒ ê²½ë¡œ (end-to-end í•™ìŠµ ì§€ì›)
- **ì¶œë ¥**: relevance score $\\in [0, 1]$

**ë°ì´í„° íë¦„ ìš”ì•½**:
1. Query í…ìŠ¤íŠ¸ â†’ BERT ì¸ì½”ë”© â†’ 768ì°¨ì› ë²¡í„°
2. ë¼ìš°íŒ… ì ìˆ˜ ê³„ì‚° â†’ Top-16 í† í° ì¸ë±ìŠ¤ ì¶”ì¶œ
3. ì„ íƒëœ í† í°ë§Œìœ¼ë¡œ ê²½ëŸ‰í™”ëœ retrieval ìˆ˜í–‰
4. ìµœì¢… ìœ ì‚¬ë„ ì ìˆ˜ ì¶œë ¥

**ì‹¤í—˜ ê²°ê³¼ (Table 1 ì°¸ì¡°)**:
- MS MARCO: **F1 87.3** (baseline 82.3 ëŒ€ë¹„ +5.0)
- ì§€ì—°ì‹œê°„: **12ms** (ê¸°ì¡´ 42ms ëŒ€ë¹„ 71% ê°ì†Œ)
- ë©”ëª¨ë¦¬: **2.3GB** (ê¸°ì¡´ 8.1GB ëŒ€ë¹„ 72% ê°ì†Œ)

---

âš ï¸ **ìœ„ ì˜ˆì‹œì²˜ëŸ¼ ëª¨ë“  ì´ë¯¸ì§€ë¥¼ 20ì¤„ ì´ìƒìœ¼ë¡œ ìƒì„¸í•˜ê²Œ ì„¤ëª…í•´ì•¼ í•©ë‹ˆë‹¤!**
`;

// Blog generation prompts by style
const BLOG_PROMPTS: Record<string, string> = {
  technical: `ë‹¹ì‹ ì€ AI/ML ë…¼ë¬¸ì„ í•´ì„¤í•˜ëŠ” ì „ë¬¸ í…Œí¬ë‹ˆì»¬ ë¸”ë¡œê·¸ ì €ìì…ë‹ˆë‹¤.

## ëª©í‘œ
ë…¼ë¬¸ì˜ í•µì‹¬ì„ ì™„ì „íˆ ì´í•´í•˜ê³ , ë…ìê°€ ë…¼ë¬¸ì„ ì½ì§€ ì•Šì•„ë„ í•µì‹¬ ë‚´ìš©ê³¼ ì˜ì˜ë¥¼ íŒŒì•…í•  ìˆ˜ ìˆë„ë¡
**ê¹Šì´ ìˆê³  êµ¬ì²´ì ì¸** ë¬¸ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.

## ì„¹ì…˜ êµ¬ì¡° (í•„ìˆ˜ ìˆœì„œ)

### 1. ë¬¸ì œì •ì˜ (3-5 ë¬¸ë‹¨)
- ê¸°ì¡´ ì‹œìŠ¤í…œ/ë°©ë²•ë¡ ì˜ í•œê³„ë¥¼ **êµ¬ì²´ì  ìˆ˜ì¹˜/ì‚¬ë¡€**ë¡œ ì œì‹œ
- ì™œ ì´ ë¬¸ì œê°€ ì¤‘ìš”í•œì§€, í•´ê²°í•˜ì§€ ëª»í•˜ë©´ ì–´ë–¤ ì‹¤ë¬´ì  ë¬¸ì œê°€ ë°œìƒí•˜ëŠ”ì§€
- ë³¸ ë…¼ë¬¸ì´ í•´ê²°í•˜ë ¤ëŠ” í•µì‹¬ ì§ˆë¬¸

### 2. ê´€ë ¨ì—°êµ¬ (2-4 ë¬¸ë‹¨)
- ê° ì„ í–‰ ì—°êµ¬ì˜ í•µì‹¬ ì•„ì´ë””ì–´ì™€ **í•œê³„ë¥¼ ëª…í™•íˆ ëŒ€ì¡°**
- ë³¸ ë…¼ë¬¸ê³¼ì˜ ì°¨ë³„ì ì„ êµ¬ì²´ì ìœ¼ë¡œ ê°•ì¡°
- í‘œë¡œ ì •ë¦¬ ê°€ëŠ¥í•˜ë©´ ì ê·¹ í™œìš©

### 3. ë°©ë²• (5-10 ë¬¸ë‹¨, ê°€ì¥ ì¤‘ìš”!)
- **ì…ë ¥â†’ì²˜ë¦¬â†’ì¶œë ¥ íë¦„**ì„ ë‹¨ê³„ë³„ë¡œ ë¶„í•´í•˜ì—¬ ì„¤ëª…
- í•˜ìœ„ ì„¹ì…˜ í™œìš©: ### 3.1, ### 3.2 ë“±
- **ëª¨ë“  ìˆ˜ì‹ì€ ë°˜ë“œì‹œ LaTeX + ìƒì„¸ ì„¤ëª…**:
  - ìˆ˜ì‹ ë°”ë¡œ ì•„ë˜ 3-5ì¤„ë¡œ ê° ë³€ìˆ˜ ì˜ë¯¸, ì…ì¶œë ¥ ì°¨ì›, ê³„ì‚° ëª©ì  ì„¤ëª…
- **ëª¨ë“  ì´ë¯¸ì§€ëŠ” ë°˜ë“œì‹œ 15-20ì¤„ ìƒì„¸ í•´ì„¤** (ì•„ë˜ ê·œì¹™ ì°¸ì¡°)

### 4. ì‹¤í—˜ (4-6 ë¬¸ë‹¨)
- ì‹¤í—˜ ì„¤ì •: ë°ì´í„°ì…‹, ë² ì´ìŠ¤ë¼ì¸, í‰ê°€ ì§€í‘œ, í•˜ì´í¼íŒŒë¼ë¯¸í„°
- **ëª¨ë“  í‘œ/ê·¸ë˜í”„ ìƒì„¸ í•´ì„¤**: ë¹„êµ ëŒ€ìƒ, ìµœê³  ê²°ê³¼, ë§ˆì§„, ì‹¤ë¬´ì  ì˜ë¯¸
- Ablation Study ê²°ê³¼ì™€ ì»´í¬ë„ŒíŠ¸ë³„ ê¸°ì—¬ë„ ë¶„ì„

### 5. ê²°ë¡  (2-3 ë¬¸ë‹¨)
- í•µì‹¬ ê¸°ì—¬ 3-4ê°œ í•­ëª©ìœ¼ë¡œ ì •ë¦¬
- ìˆ˜ì¹˜ì  ì„±ê³¼ ì¬ê°•ì¡°
- í•œê³„ì  ì†”ì§í•˜ê²Œ ê¸°ìˆ 

### 6. ì¸ì‚¬ì´íŠ¸ (2-4 ë¬¸ë‹¨)
- ê¸°ìˆ ì  ì¸ì‚¬ì´íŠ¸: ì™œ ì´ ë°©ë²•ì´ ì‘ë™í•˜ëŠ”ê°€?
- ì‹¤ë¬´ì  í•¨ì˜: ì–´ë–¤ ì‹œìŠ¤í…œ/ì„œë¹„ìŠ¤ì— ì ìš© ê°€ëŠ¥í•œê°€?
- í–¥í›„ ì—°êµ¬ ë°©í–¥
${MARKDOWN_FORMATTING_RULES}
${IMAGE_DESCRIPTION_INSTRUCTIONS}
${OBSIDIAN_FORMAT_INSTRUCTIONS}

## ì¶”ê°€ ê·œì¹™
- ì œê³µëœ ìë£Œ ë°–ì˜ ë‚´ìš© ì¶”ì¸¡ ê¸ˆì§€
- ë¬¸ì²´: í•œêµ­ì–´, ì „ë¬¸ ë¸”ë¡œê·¸ ìŠ¤íƒ€ì¼ (ë‹¨ì •ì ì´ê³  ëª…í™•í•˜ê²Œ)
- ê° ì„¹ì…˜ì€ ìµœì†Œ 200ì ì´ìƒ (í”¼ìƒì ì¸ ìš”ì•½ ê¸ˆì§€)`,

  summary: `You are creating a concise summary blog post about an academic paper for Obsidian.

STRUCTURE:
1. **One-Line Summary** (in a callout)
2. **Problem** (What problem does this solve?)
3. **Solution** (What's the key idea? with [[wikilinks]])
4. **Results** (What did they achieve?)
5. **Why It Matters**
6. **Related Concepts** ([[wikilinks]] list)

STYLE:
- Maximum 500 words
- Focus on the "so what?" factor
- No technical jargon unless absolutely necessary
- Suitable for sharing on social media
- Use Obsidian callouts for the summary
${OBSIDIAN_FORMAT_INSTRUCTIONS}`,

  tutorial: `You are creating a tutorial-style blog post based on an academic paper for Obsidian.

STRUCTURE:
1. **What You'll Learn** (callout box)
2. **Prerequisites** (with [[wikilinks]] to background knowledge)
3. **Step 1: Understanding the Problem**
4. **Step 2: The Core Idea**
5. **Step 3: How It Works** (with diagrams descriptions)
6. **Step 4: Implementation Notes** (code blocks)
7. **Step 5: Hands-on Exercise** (suggested experiments in callout)
8. **Further Reading** ([[wikilinks]] and external links)
9. **Related Concepts** ([[wikilinks]] list)

STYLE:
- Write as if teaching a workshop
- Use > [!tip] callouts for "Try This" exercises
- Explain every acronym on first use with [[wikilink]]
- Use > [!warning] callouts for "Common Mistakes to Avoid"
${IMAGE_DESCRIPTION_INSTRUCTIONS}
${OBSIDIAN_FORMAT_INSTRUCTIONS}`,
};

const LANGUAGE_INSTRUCTIONS: Record<string, string> = {
  ko: "Write the entire blog post in Korean (í•œêµ­ì–´). Use natural Korean expressions suitable for a technical blog.",
  en: "Write the entire blog post in English.",
  bilingual: `Write the blog post with:
- Main content in Korean (í•œêµ­ì–´)
- Technical terms as "English(í•œêµ­ì–´)" format
- Include an English abstract at the top`,
};

/**
 * Blog Generator Service
 */
export class BlogGeneratorService {
  private app: App;
  private settings: PaperProcessorSettings;
  private onProgress?: (progress: BlogProgress) => void;

  constructor(app: App, settings: PaperProcessorSettings) {
    this.app = app;
    this.settings = settings;
  }

  setProgressCallback(callback: (progress: BlogProgress) => void): void {
    this.onProgress = callback;
  }

  private updateProgress(stage: BlogProgress["stage"], message: string, percent: number): void {
    if (this.onProgress) {
      this.onProgress({ stage, message, percent });
    }
  }

  /**
   * Generate a blog post from a paper using Multimodal API
   */
  async generate(paperFolder: string): Promise<BlogResult> {
    if (!this.settings.geminiApiKey) {
      return {
        success: false,
        error: "Gemini API key not configured. Please set it in plugin settings.",
      };
    }

    try {
      this.updateProgress("analyzing", `ğŸ“‚ Reading from folder: ${paperFolder}`, 5);

      // Try to read translated content first, fall back to original
      const content = await this.getPaperContent(paperFolder);
      if (!content) {
        return {
          success: false,
          error: "No paper content found. Run OCR or provide markdown files.",
        };
      }
      const contentLength = content.length;
      const wordCount = content.split(/\s+/).length;
      this.updateProgress("analyzing", `ğŸ“„ Paper content loaded: ${wordCount.toLocaleString()} words (${(contentLength / 1024).toFixed(1)}KB)`, 10);

      // Read metadata if available
      const metadata = await this.getMetadata(paperFolder);
      if (metadata) {
        this.updateProgress("analyzing", `ğŸ“‹ Metadata: "${metadata.title || 'Unknown'}"`, 15);
        if (metadata.arxiv_id) {
          this.updateProgress("analyzing", `ğŸ”— arXiv ID: ${metadata.arxiv_id}`, 17);
        }
      } else {
        this.updateProgress("analyzing", "âš ï¸ No metadata.json found", 15);
      }

      // Load images with Base64 data for multimodal API
      this.updateProgress("analyzing", "ğŸ–¼ï¸ Loading images for multimodal analysis...", 20);
      const images = await this.loadImagesWithData(paperFolder, 10);

      if (images.length > 0) {
        this.updateProgress("analyzing", `ğŸ–¼ï¸ Loaded ${images.length} images: ${images.slice(0, 3).map(i => i.name).join(", ")}${images.length > 3 ? "..." : ""}`, 22);

        // Analyze each image individually (Deep Analysis) with text alignment
        const client = new GeminiClient(this.settings.geminiApiKey, this.settings.blogModel);

        for (let i = 0; i < images.length; i++) {
          const img = images[i];
          this.updateProgress("analyzing", `ğŸ” Deep analyzing image (${i + 1}/${images.length}): ${img.name}`, 25 + (i * 3));

          try {
            // Pass full content for context extraction per image
            const analysis = await this.analyzeImage(client, img, content, metadata);
            img.analysis = analysis;
            this.updateProgress("analyzing", `âœ… Analyzed: ${img.name}`, 25 + ((i + 1) * 3));
          } catch (err) {
            console.error(`Failed to analyze image ${img.name}:`, err);
            img.analysis = "(ë¶„ì„ ì‹¤íŒ¨)";
          }
        }
      } else {
        this.updateProgress("analyzing", "âš ï¸ No images found in images/ folder", 25);
      }

      this.updateProgress("generating", `ğŸ¤– Model: ${this.settings.blogModel}`, 55);
      this.updateProgress("generating", `ğŸŒ Language: ${this.settings.blogLanguage}, Style: ${this.settings.blogStyle}`, 58);
      this.updateProgress("generating", "â³ Generating blog with multimodal API (this may take 1-2 minutes)...", 60);

      // Build prompt with image analysis results
      const stylePrompt = BLOG_PROMPTS[this.settings.blogStyle] || BLOG_PROMPTS.technical;
      const langInstruction = LANGUAGE_INSTRUCTIONS[this.settings.blogLanguage] || LANGUAGE_INSTRUCTIONS.ko;

      // Build system prompt with image instructions
      const imageInstructions = images.length > 0 ? `

## IMAGES INFORMATION
You will receive ${images.length} images with their analysis.
- Each image is labeled as "IMAGE N: images/filename"
- The analysis is provided right before each image
- You MUST include ALL images in your blog post using Obsidian embed syntax: ![[images/filename]]
- For each image, write 20-30 lines of detailed explanation based on the analysis AND the actual image
- Place images in appropriate sections (architecture in Method, results in Experiment, etc.)
` : "";

      const systemPrompt = `${stylePrompt}

${langInstruction}
${imageInstructions}

---
PAPER TITLE: ${metadata?.title || "Unknown"}
${metadata?.title_ko ? `KOREAN TITLE: ${metadata.title_ko}` : ""}
---`;

      // Call Gemini with interleaved images (Multimodal)
      const client = new GeminiClient(this.settings.geminiApiKey, this.settings.blogModel);
      this.updateProgress("generating", `ğŸ“ Using interleaved multimodal API with ${images.length} images`, 65);

      const startTime = Date.now();

      // Use interleaved multimodal API if we have images
      let result;
      if (images.length > 0) {
        // Prepare interleaved format: image label + analysis + actual image
        const imagesWithAnalysis = images.map(img => ({
          image: { mimeType: img.mimeType, data: img.data },
          label: img.relativePath,
          analysis: img.analysis || "(ë¶„ì„ ì—†ìŒ)",
        }));

        result = await client.generateContentWithInterleavedImages(
          systemPrompt,
          imagesWithAnalysis,
          content,
          {
            temperature: 0.7,
            maxOutputTokens: 8192,
          }
        );
      } else {
        const fullPrompt = `${systemPrompt}\n\nPAPER CONTENT:\n${content}\n\n---\nGenerate the blog post now. Output markdown only, no explanations.`;
        result = await client.generateContent(fullPrompt, {
          temperature: 0.7,
          maxOutputTokens: 8192,
        });
      }

      const elapsed = ((Date.now() - startTime) / 1000).toFixed(1);

      if (!result.success || !result.data) {
        this.updateProgress("generating", `âŒ API Error: ${result.error}`, 70);
        return {
          success: false,
          error: result.error || "Blog generation failed",
        };
      }

      const outputLength = result.data.length;
      this.updateProgress("generating", `âœ… Response received in ${elapsed}s (${(outputLength / 1024).toFixed(1)}KB)`, 85);
      this.updateProgress("saving", "ğŸ’¾ Processing and saving blog post...", 90);

      // Clean up response (remove code blocks if present)
      let blogContent = result.data;
      if (blogContent.startsWith("```")) {
        blogContent = blogContent.replace(/```markdown?\n?/g, "").replace(/```$/g, "").trim();
      }

      // Add frontmatter (pass content for topic tag extraction)
      const frontmatter = this.generateFrontmatter(metadata, content);
      const finalContent = `${frontmatter}\n\n${blogContent}`;

      // Save blog post
      const blogPath = `${paperFolder}/blog.md`;
      const existing = this.app.vault.getAbstractFileByPath(blogPath);
      if (existing instanceof TFile) {
        await this.app.vault.modify(existing, finalContent);
        this.updateProgress("saving", `ğŸ“ Updated existing: ${blogPath}`, 95);
      } else {
        await this.app.vault.create(blogPath, finalContent);
        this.updateProgress("saving", `ğŸ“ Created new file: ${blogPath}`, 95);
      }

      const finalWordCount = finalContent.split(/\s+/).length;
      this.updateProgress("complete", `âœ… Blog post generated! (${finalWordCount.toLocaleString()} words)`, 100);
      this.updateProgress("complete", `ğŸ–¼ï¸ Included ${images.length} images with detailed analysis`, 100);
      showSuccess("Blog post generated successfully");

      return {
        success: true,
        content: finalContent,
        path: blogPath,
      };
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      showError(errorMessage);
      return { success: false, error: errorMessage };
    }
  }

  /**
   * Get paper content (prefer translated, fall back to original)
   */
  private async getPaperContent(folder: string): Promise<string | null> {
    const priorities = ["translated.md", "translated_raw.md", "original.md"];

    for (const filename of priorities) {
      const path = `${folder}/${filename}`;
      const file = this.app.vault.getAbstractFileByPath(path);
      if (file instanceof TFile) {
        return await this.app.vault.read(file);
      }
    }

    return null;
  }

  /**
   * Get paper metadata
   */
  private async getMetadata(folder: string): Promise<Record<string, string> | null> {
    const path = `${folder}/metadata.json`;
    const file = this.app.vault.getAbstractFileByPath(path);

    if (file instanceof TFile) {
      try {
        const content = await this.app.vault.read(file);
        return JSON.parse(content);
      } catch {
        return null;
      }
    }

    return null;
  }

  /**
   * Load images with Base64 data for multimodal API
   */
  private async loadImagesWithData(folder: string, maxImages = 10, maxImageBytes = 4 * 1024 * 1024): Promise<Array<ImageData & { name: string; relativePath: string; analysis?: string }>> {
    const imagesFolder = this.app.vault.getAbstractFileByPath(`${folder}/images`);

    if (!(imagesFolder instanceof TFolder)) {
      return [];
    }

    const imageFiles: TFile[] = [];
    for (const child of imagesFolder.children) {
      if (child instanceof TFile && /\.(png|jpg|jpeg|gif|webp)$/i.test(child.name)) {
        imageFiles.push(child);
      }
    }

    // Natural sort (img-1, img-2, ..., img-10 instead of img-1, img-10, img-2)
    imageFiles.sort((a, b) => {
      const numA = parseInt(a.name.match(/\d+/)?.[0] || "0", 10);
      const numB = parseInt(b.name.match(/\d+/)?.[0] || "0", 10);
      return numA - numB;
    });
    const filesToProcess = imageFiles.slice(0, maxImages);

    const images: Array<ImageData & { name: string; relativePath: string; analysis?: string }> = [];

    for (const file of filesToProcess) {
      try {
        // Check file size
        const stats = await this.app.vault.adapter.stat(`${folder}/images/${file.name}`);
        if (stats && stats.size > maxImageBytes) {
          console.log(`âš ï¸ Skipping large image: ${file.name} (${(stats.size / 1024 / 1024).toFixed(2)}MB)`);
          continue;
        }

        // Read binary and convert to base64
        const arrayBuffer = await this.app.vault.readBinary(file);
        const base64 = this.arrayBufferToBase64(arrayBuffer);

        // Determine MIME type
        const ext = file.extension.toLowerCase();
        const mimeTypes: Record<string, string> = {
          png: "image/png",
          jpg: "image/jpeg",
          jpeg: "image/jpeg",
          gif: "image/gif",
          webp: "image/webp",
        };
        const mimeType = mimeTypes[ext] || "image/png";

        images.push({
          name: file.name,
          relativePath: `images/${file.name}`,
          mimeType,
          data: base64,
        });
      } catch (err) {
        console.error(`Failed to load image ${file.name}:`, err);
      }
    }

    return images;
  }

  /**
   * Convert ArrayBuffer to Base64 string
   */
  private arrayBufferToBase64(buffer: ArrayBuffer): string {
    const bytes = new Uint8Array(buffer);
    let binary = "";
    for (let i = 0; i < bytes.byteLength; i++) {
      binary += String.fromCharCode(bytes[i]);
    }
    return btoa(binary);
  }

  /**
   * Extract context from paper text for a specific image
   * Finds Figure/Fig references and extracts surrounding text
   */
  private extractImageContext(content: string, imageName: string): string {
    // Extract number from filename (e.g., "img-1.jpeg" -> "1")
    const numMatch = imageName.match(/(\d+)/);
    if (!numMatch) {
      return "";
    }

    const num = numMatch[1];
    const patterns = [
      new RegExp(`Figure\\s*${num}[^0-9]`, "gi"),
      new RegExp(`Fig\\.?\\s*${num}[^0-9]`, "gi"),
      new RegExp(`ê·¸ë¦¼\\s*${num}[^0-9]`, "gi"),
    ];

    const lines = content.split("\n");
    const relevantChunks: string[] = [];

    for (let i = 0; i < lines.length; i++) {
      const line = lines[i];
      for (const pattern of patterns) {
        if (pattern.test(line)) {
          // Get 2 lines before and 4 lines after
          const start = Math.max(0, i - 2);
          const end = Math.min(lines.length, i + 5);
          const chunk = lines.slice(start, end).join("\n").trim();
          if (chunk && !relevantChunks.includes(chunk)) {
            relevantChunks.push(chunk);
          }
          break;
        }
      }
    }

    if (relevantChunks.length > 0) {
      return relevantChunks.join("\n---\n");
    }

    return "(No direct text reference found)";
  }

  /**
   * Analyze a single image using Gemini multimodal API
   * Uses extracted context from paper text
   */
  private async analyzeImage(client: GeminiClient, image: ImageData & { name: string }, fullContent: string, metadata: Record<string, string> | null): Promise<string> {
    // Extract specific context for this image
    const imageContext = this.extractImageContext(fullContent, image.name);
    const titleContext = `Title: ${metadata?.title || 'Unknown'}`;

    const paperContext = imageContext !== "(No direct text reference found)"
      ? `${titleContext}\n\n## Text References to This Figure\n${imageContext}`
      : `${titleContext}\n\nAbstract/Content:\n${fullContent.slice(0, 1500)}`;

    const analysisPrompt = `You are an expert at analyzing academic paper figures.

Extract ALL details from this image and provide structured analysis:

## Visual Inventory
[List all visible elements: text, shapes, data points, colors, annotations]

## Core Findings
[3-5 key takeaways]

## Detailed Analysis
[Paragraph explaining the image comprehensively]

## Connection to Paper
[How this supports the paper's argument based on the provided context]

## Technical Details
[Numbers, dimensions, hyperparameters extracted]

Output in structured markdown.`;

    const result = await client.analyzeImage(
      { mimeType: image.mimeType, data: image.data },
      paperContext,
      analysisPrompt
    );

    if (result.success && result.data) {
      return result.data;
    }
    return "(ë¶„ì„ ì‹¤íŒ¨)";
  }

  /**
   * Generate YAML frontmatter for blog post with Obsidian tags
   */
  private generateFrontmatter(metadata: Record<string, any> | null, content?: string): string {
    const now = new Date().toISOString().split("T")[0];
    const title = metadata?.title || "Untitled Paper";
    const titleKo = metadata?.title_ko || "";

    // Collect all tags
    const tags = new Set<string>(["paper-review", this.settings.blogStyle]);

    // Add tags from arXiv categories
    if (metadata?.categories && Array.isArray(metadata.categories)) {
      const categoryTags = arxivCategoriesToTags(metadata.categories);
      categoryTags.forEach(tag => tags.add(tag.replace(/^#/, "")));
    }

    // Add topic tags from content analysis
    if (content) {
      const topicTags = extractTopicTags(content);
      topicTags.forEach(tag => tags.add(tag.replace(/^#/, "")));
    }

    // Add tags from title
    if (title) {
      const titleTags = extractTopicTags(title);
      titleTags.forEach(tag => tags.add(tag.replace(/^#/, "")));
    }

    const tagsArray = Array.from(tags);

    return `---
title: "${this.escapeYaml(titleKo || title)}"
date: ${now}
tags:
${tagsArray.map(t => `  - ${t}`).join("\n")}
paper_title: "${this.escapeYaml(title)}"
${titleKo ? `paper_title_ko: "${this.escapeYaml(titleKo)}"` : ""}
${metadata?.arxiv_id ? `arxiv_id: "${metadata.arxiv_id}"` : ""}
${metadata?.arxiv_id ? `arxiv_url: "https://arxiv.org/abs/${metadata.arxiv_id}"` : ""}
style: ${this.settings.blogStyle}
language: ${this.settings.blogLanguage}
---`;
  }

  private escapeYaml(str: string): string {
    return str.replace(/"/g, '\\"').replace(/\n/g, " ");
  }
}
